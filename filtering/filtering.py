import os
import json
from dotenv import load_dotenv
from google import genai
from typing import List, Dict, Any, Optional

from filtering.prompts import FILTER_PROMPT_HEADER, FILTER_PROMPT_FOOTER
from filtering.schemas import FilteredSound, FilterResponse


def get_gemini_model(api_key: Optional[str] = None):
    """
    Configure and return a Gemini model.

    Args:
        api_key: Google API key. If None, uses the GOOGLE_API_KEY environment variable

    Returns:
        Configured Gemini model instance
    """
    load_dotenv()
    if api_key is None:
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError(
                "GOOGLE_API_KEY must be defined in the environment or passed as a parameter"
            )
    return genai.Client()


def create_prompt(
    similarity_data: List[Dict[str, Any]],
    max_sounds: Optional[int] = None,
    user_prompt: Optional[str] = None,
) -> str:
    """
    Create the prompt for the LLM.

    Args:
        similarity_data: Similarity data between sentences and sounds
        max_sounds: Maximum number of sentences to select (optional)
        user_prompt: Additional user instructions to refine filtering (optional)

    Returns:
        Formatted prompt for the LLM
    """
    # Build dynamic instructions
    max_sounds_instruction = ""
    if max_sounds is not None:
        max_sounds_instruction = (
            f"\n- You should prioritize the top {max_sounds} most impactful sentences"
        )

    user_context = ""
    if user_prompt:
        user_context = f"\n\nUSER SPECIFIC INSTRUCTIONS:\n{user_prompt}\n"

    # Build prompt header with dynamic parts
    prompt = FILTER_PROMPT_HEADER.format(
        max_sounds_instruction=max_sounds_instruction, user_context=user_context
    )

    # Add sentence data
    for item in similarity_data:
        prompt += f"\n--- Sentence {item['speech_index']} ---\n"
        prompt += f'Text: "{item["speech_text"]}"\n'
        prompt += f"Suggested sounds:\n"
        for i, match in enumerate(item["top_matches"][:3], 1):  # Top 3 only
            prompt += f"  {i}. {match['sound_title']} (similarity: {match['similarity']:.2f})\n"
            prompt += f"     Description: {match['sound_description']}\n"
            prompt += f"     URL: {match['audio_url_wav']}\n"

    # Add footer
    prompt += FILTER_PROMPT_FOOTER

    return prompt


def filter_sounds(
    similarity_data: List[Dict[str, Any]],
    max_sounds: Optional[int] = 4,
    api_key: Optional[str] = None,
    user_prompt: Optional[str] = None,
    output_file: Optional[str] = None,
) -> Dict[str, Any]:
    """
    Filter sounds using the LLM with a relevance ranking system.

    Args:
        similarity_data: Data from the similarity.json file
        max_sounds: Number of sentences to prioritize (optional, serves as a guide for the LLM)
        api_key: Google API key (optional)
        user_prompt: Additional instructions to refine filtering (optional)
        output_file: Output file path. If None, uses 'llm_filtering/output/filtered_sounds.json'

    Returns:
        Dictionary with all sounds ranked by unique rank (1 = best, 2 = 2nd best, etc.)
    """
    model = get_gemini_model(api_key)
    prompt = create_prompt(similarity_data, max_sounds, user_prompt)
    response = model.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt,
        config={
            "response_mime_type": "application/json",
            "response_json_schema": FilterResponse.model_json_schema(),
        },
    )
    # response = model.generate_content(prompt)

    # Parse and validate the structured JSON response using Pydantic
    try:
        llm_result = FilterResponse.model_validate_json(response.text)
    except Exception as e:
        print(f"Error validating LLM filter response: {e}")
        raise e

    # Reconstruct complete data from indexes
    # to avoid LLM hallucinations
    result = {"filtered_sounds": []}

    for item in llm_result.filtered_sounds:
        try:
            speech_idx = item.speech_index
            sound_idx = item.selected_sound_index

            # Retrieve original data
            original_data = similarity_data[speech_idx]
            selected_sound = original_data["top_matches"][sound_idx]

            # Build entry with real data (not generated by the LLM)
            result["filtered_sounds"].append(
                {
                    "speech_index": speech_idx,
                    "speech_text": original_data["speech_text"],
                    "relevance_rank": item.relevance_rank,
                    "target_word": item.target_word,
                    "should_add_sound": item.should_add_sound,
                    "selected_sound": {
                        "sound_title": selected_sound["sound_title"],
                        "sound_description": selected_sound["sound_description"],
                        "audio_url_wav": selected_sound["sound_location"],
                        "similarity_score": selected_sound["similarity"],
                    },
                    "reasoning": item.reasoning,
                }
            )
        except Exception as e:
            print(f"Error processing filtered sound at index {item.speech_index}: {e}")
            pass

    # Sort by ascending relevance rank (1 = best)
    result["filtered_sounds"].sort(key=lambda x: x["relevance_rank"])

    # Automatic save to output/
    if output_file is None:
        output_file = "llm_filtering/output/filtered_sounds.json"

    output_dir = os.path.dirname(output_file)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    print(f"Result saved to {output_file}")

    return result


if __name__ == "__main__":
    with open("similarity/output/similarity.json", "r", encoding="utf-8") as f:
        sample_data = json.load(f)
    result = filter_sounds(sample_data, max_sounds=2)
    print(json.dumps(result, indent=2, ensure_ascii=False))
