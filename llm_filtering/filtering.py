import os
import json
from dotenv import load_dotenv
import google.generativeai as genai
from typing import List, Dict, Any, Optional

from llm_filtering.prompts import FILTER_PROMPT_HEADER, FILTER_PROMPT_FOOTER


def get_gemini_model(api_key: Optional[str] = None) -> genai.GenerativeModel:
    """
    Configure and return a Gemini model.

    Args:
        api_key: Google API key. If None, uses the GOOGLE_API_KEY environment variable

    Returns:
        Configured Gemini model instance
    """
    load_dotenv()
    if api_key is None:
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError(
                "GOOGLE_API_KEY must be defined in the environment or passed as a parameter"
            )

    genai.configure(api_key=api_key)
    return genai.GenerativeModel("gemini-2.5-flash-lite")


def create_prompt(
    similarity_data: List[Dict[str, Any]],
    max_sounds: Optional[int] = None,
    user_prompt: Optional[str] = None,
) -> str:
    """
    Create the prompt for the LLM.

    Args:
        similarity_data: Similarity data between sentences and sounds
        max_sounds: Maximum number of sentences to select (optional)
        user_prompt: Additional user instructions to refine filtering (optional)

    Returns:
        Formatted prompt for the LLM
    """
    # Build dynamic instructions
    max_sounds_instruction = ""
    if max_sounds is not None:
        max_sounds_instruction = (
            f"\n- You should prioritize the top {max_sounds} most impactful sentences"
        )

    user_context = ""
    if user_prompt:
        user_context = f"\n\nUSER SPECIFIC INSTRUCTIONS:\n{user_prompt}\n"

    # Build prompt header with dynamic parts
    prompt = FILTER_PROMPT_HEADER.format(
        max_sounds_instruction=max_sounds_instruction,
        user_context=user_context
    )

    # Add sentence data
    for item in similarity_data:
        prompt += f"\n--- Sentence {item['speech_index']} ---\n"
        prompt += f'Text: "{item["speech_text"]}"\n'
        prompt += f"Suggested sounds:\n"
        for i, match in enumerate(item["top_matches"][:3], 1):  # Top 3 only
            prompt += f"  {i}. {match['sound_title']} (similarity: {match['similarity']:.2f})\n"
            prompt += f"     Description: {match['sound_description']}\n"
            prompt += f"     URL: {match['audio_url_wav']}\n"

    # Add footer
    prompt += FILTER_PROMPT_FOOTER

    return prompt


def clean_json_response(response_text: str) -> str:
    """
    Clean the LLM response to extract pure JSON.

    Args:
        response_text: Raw LLM response

    Returns:
        Cleaned JSON
    """
    response_text = response_text.strip().replace(' ""', ' "')

    # Clean markdown if present
    if response_text.startswith("```"):
        lines = response_text.split("\n")
        response_text = "\n".join(lines[1:-1])
        if response_text.startswith("json"):
            response_text = response_text[4:].strip()

    return response_text


def filter_sounds(
    similarity_data: List[Dict[str, Any]],
    max_sounds: Optional[int] = 4,
    api_key: Optional[str] = None,
    user_prompt: Optional[str] = None,
    output_file: Optional[str] = None,
) -> Dict[str, Any]:
    """
    Filter sounds using the LLM with a relevance ranking system.

    Args:
        similarity_data: Data from the similarity.json file
        max_sounds: Number of sentences to prioritize (optional, serves as a guide for the LLM)
        api_key: Google API key (optional)
        user_prompt: Additional instructions to refine filtering (optional)
        output_file: Output file path. If None, uses 'llm_filtering/output/filtered_sounds.json'

    Returns:
        Dictionary with all sounds ranked by unique rank (1 = best, 2 = 2nd best, etc.)
    """
    model = get_gemini_model(api_key)
    prompt = create_prompt(similarity_data, max_sounds, user_prompt)
    response = model.generate_content(prompt)

    # TODO : this step should not be ! JSON response expected as is.
    response_text = clean_json_response(response.text)

    print(response)
    print()
    print(response_text)
    try:
        llm_result = json.loads(response_text)
    except json.JSONDecodeError as e:
        print("Error decoding LLM filter response")
        print(f"First 200 chars of cleaned response: {response_text[:200]}")
        raise e
    # Reconstruct complete data from indexes
    # to avoid LLM hallucinations
    result = {"filtered_sounds": []}

    for item in llm_result["filtered_sounds"]:
        try:  # TODO : this is a quickfix, JSON should be well structured
            speech_idx = item["speech_index"]
            sound_idx = item["selected_sound_index"]

            # Retrieve original data
            original_data = similarity_data[speech_idx]
            selected_sound = original_data["top_matches"][sound_idx]

            # Build entry with real data (not generated by the LLM)
            result["filtered_sounds"].append(
                {
                    "speech_index": speech_idx,
                    "speech_text": original_data["speech_text"],
                    "relevance_rank": item["relevance_rank"],
                    "target_word": item["target_word"],
                    "should_add_sound": item["should_add_sound"],
                    "selected_sound": {
                        "sound_title": selected_sound["sound_title"],
                        "sound_description": selected_sound["sound_description"],
                        "audio_url_wav": selected_sound["audio_url_wav"],
                        "similarity_score": selected_sound["similarity"],
                    },
                    "reasoning": item["reasoning"],
                }
            )
        except:
            print("TODO : LLM filter did not output expected JSON struct")
            pass

    # Sort by ascending relevance rank (1 = best)
    result["filtered_sounds"].sort(key=lambda x: x["relevance_rank"])

    # Automatic save to output/
    if output_file is None:
        output_file = "llm_filtering/output/filtered_sounds.json"

    output_dir = os.path.dirname(output_file)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    print(f"Result saved to {output_file}")

    return result
