{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut27u1uPeZPc",
        "outputId": "72648e25-fc49-4373-b65a-5cbe21dc4e41"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Charger les données déjà collectées\n",
        "df = pd.read_csv(\"soundbible_details_from_section.csv\")\n",
        "\n",
        "cleaned_descriptions = []\n",
        "\n",
        "for desc in df[\"description\"]:\n",
        "    if pd.isna(desc):\n",
        "        cleaned_descriptions.append(None)\n",
        "        continue\n",
        "\n",
        "    pattern = r'[^.!?]*[Dd]ownload[^.!?]*[.!?]\\s*'\n",
        "    desc_filtered = re.sub(pattern, '', desc)\n",
        "\n",
        "    # Then try to match the pattern\n",
        "    match = re.search(r\"Free\\.\\s*Get\\s*(.*?)\\s*in Wav or MP3\", desc_filtered)\n",
        "    if match:\n",
        "        cleaned_descriptions.append(match.group(1).strip())\n",
        "    else:\n",
        "        cleaned_descriptions.append(desc_filtered)\n",
        "\n",
        "df[\"clean_description\"] = cleaned_descriptions\n",
        "\n",
        "# Sauvegarder dans un nouveau fichier\n",
        "df.to_csv(\"soundbible_details_clean.csv\", index=False)\n",
        "\n",
        "print(df[[\"title\", \"clean_description\"]].head())\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_YbqDTCiRQ-",
        "outputId": "6f820bc9-bebc-4c49-fc7e-040b624daa62"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Charger la liste des pages individuelles\n",
        "df = pd.read_csv(\"soundbible_links.csv\")\n",
        "\n",
        "session = requests.Session()\n",
        "session.headers.update({\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "                  \"Chrome/124.0.0.0 Safari/537.36\"\n",
        "})\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    href = row[\"href\"]\n",
        "    title = row[\"title\"]\n",
        "    url = f\"https://soundbible.com/{href}\"\n",
        "\n",
        "    try:\n",
        "        response = session.get(url, timeout=12)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to fetch {url} (status {response.status_code})\")\n",
        "            continue\n",
        "\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # --- Description depuis la section #course-details ---\n",
        "        # On cible le premier <p> dans la colonne de gauche (col-lg-8)\n",
        "        description = None\n",
        "        section = soup.find(\"section\", id=\"course-details\")\n",
        "        if section:\n",
        "            p_tag = section.select_one(\".col-lg-8 p\")\n",
        "            if not p_tag:\n",
        "                # fallback: premier <p> sous la section si la structure diffère\n",
        "                p_tag = section.find(\"p\")\n",
        "            if p_tag:\n",
        "                # Nettoyage des espaces / sauts de ligne\n",
        "                description = \" \".join(p_tag.stripped_strings)\n",
        "\n",
        "        # --- Keywords (on conserve la récupération via meta) ---\n",
        "        kw_tag = soup.find(\"meta\", {\"name\": \"keywords\"})\n",
        "        keywords = kw_tag[\"content\"].split(\",\") if kw_tag and kw_tag.has_attr(\"content\") else []\n",
        "\n",
        "        # --- Durée audio (dans la section, plus précis) ---\n",
        "        time_tag = soup.select_one(\"#course-details .total-time\")\n",
        "        if not time_tag:\n",
        "            # fallback global si besoin\n",
        "            time_tag = soup.find(\"div\", {\"class\": \"total-time\"})\n",
        "        length = time_tag.get_text(strip=True) if time_tag else None\n",
        "\n",
        "        results.append({\n",
        "            \"title\": title,\n",
        "            \"href\": href,\n",
        "            \"url\": url,\n",
        "            \"description\": description,  # <-- maintenant depuis #course-details\n",
        "            \"keywords\": [k.strip() for k in keywords if k.strip()],\n",
        "            \"length\": length\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error on {url}: {e}\")\n",
        "\n",
        "    # Politesse pour éviter de surcharger le site\n",
        "    time.sleep(1)\n",
        "\n",
        "# DataFrame et export\n",
        "df_details = pd.DataFrame(results)\n",
        "print(df_details.head())\n",
        "\n",
        "# Nouveau fichier pour ne pas écraser l'ancien\n",
        "df_details.to_csv(\"soundbible_details_from_section.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_details[\"description\"].loc[df_details[\"description\"].str.contains(\"download\")].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-FQg-vZ9UW3",
        "outputId": "dad3dd9f-124b-46d1-c865-913bcfbb5a4a"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "from urllib.parse import urljoin, urlparse, unquote\n",
        "\n",
        "INPUT_CSV = \"soundbible_details_from_section.csv\"\n",
        "OUTPUT_CSV = \"soundbible_audio_files.csv\"\n",
        "BASE_URL = \"https://soundbible.com/\"\n",
        "\n",
        "# Sélecteurs fournis (sélecteur principal)\n",
        "SEL_AUDIO_PRIMARY = \"#ag1 > div:nth-child(2) > div > div > div > div.the-media > audio > source\"\n",
        "SEL_TIME_PRIMARY = \"#ag1 > div:nth-child(2) > div > div > div > div.ap-controls.scrubbar-loaded > div.scrubbar > div.total-time\"\n",
        "\n",
        "# Fallback selectors\n",
        "FALLBACK_AUDIO_SELECTORS = [\n",
        "    \"div.audioplayer-inner .the-media audio source\",\n",
        "    \"div.audioplayer-inner audio source\",\n",
        "    \"#ag1 source\",\n",
        "    \"audio source\"\n",
        "]\n",
        "FALLBACK_TIME_SELECTORS = [\n",
        "    \"div.audioplayer-inner .total-time\",\n",
        "    \".total-time\",\n",
        "    \"div.total-time\"\n",
        "]\n",
        "\n",
        "session = requests.Session()\n",
        "session.headers.update({\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "                  \"Chrome/124.0.0.0 Safari/537.36\"\n",
        "})\n",
        "\n",
        "# Charger le CSV input\n",
        "df_in = pd.read_csv(INPUT_CSV)\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx, row in df_in.iterrows():\n",
        "    # obtenir l'URL (ou construire depuis href si nécessaire)\n",
        "    url = None\n",
        "    if \"url\" in row and pd.notna(row[\"url\"]):\n",
        "        url = row[\"url\"]\n",
        "    elif \"href\" in row and pd.notna(row[\"href\"]):\n",
        "        url = urljoin(BASE_URL, str(row[\"href\"]))\n",
        "    else:\n",
        "        print(f\"[{idx}] Aucun 'url' ni 'href' trouvé, skip\")\n",
        "        results.append({\"index\": idx, \"url\": None, \"audio_length\": None, \"audio_file\": None, \"audio_url\": None})\n",
        "        continue\n",
        "\n",
        "    audio_file_name = None\n",
        "    audio_url_full = None\n",
        "    audio_length = None\n",
        "\n",
        "    try:\n",
        "        resp = session.get(url, timeout=15)\n",
        "        if resp.status_code != 200:\n",
        "            print(f\"  → status {resp.status_code}, skip\")\n",
        "            results.append({\"index\": idx, \"url\": url, \"audio_length\": None, \"audio_file\": None, \"audio_url\": None})\n",
        "            continue\n",
        "\n",
        "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "        # 1) essayer le sélecteur principal pour le source audio\n",
        "        src = None\n",
        "        tag = soup.select_one(SEL_AUDIO_PRIMARY)\n",
        "        if tag and tag.has_attr(\"src\"):\n",
        "            src = tag[\"src\"]\n",
        "            # debug\n",
        "            # print(\"  → trouvé audio via SEL_AUDIO_PRIMARY\")\n",
        "        else:\n",
        "            # fallback - chercher un attribut data-source sur un parent (cas fréquent)\n",
        "            # ex: <div ... data-source=\"mp3/airplane-takeoff_daniel_simion.mp3\" ...>\n",
        "            ds_tag = soup.select_one(\"#ag1 [data-source], [data-source]\")\n",
        "            if ds_tag and ds_tag.has_attr(\"data-source\"):\n",
        "                data_src = ds_tag[\"data-source\"]\n",
        "                # le contenu peut être JSON-like; on cherche le premier mp3/wav\n",
        "                m = re.search(r\"(?:mp3|wav)/[A-Za-z0-9._\\-\\s()%]+(?:\\.mp3|\\.wav)\", data_src, re.IGNORECASE)\n",
        "                if m:\n",
        "                    src = m.group(0)\n",
        "                    # print(\"  → trouvé audio via data-source fallback\")\n",
        "            # si toujours rien, essayer autres fallback selectors\n",
        "        if not src:\n",
        "            for s in FALLBACK_AUDIO_SELECTORS:\n",
        "                t = soup.select_one(s)\n",
        "                if t and t.has_attr(\"src\"):\n",
        "                    src = t[\"src\"]\n",
        "                    # print(f\"  → trouvé audio via fallback {s}\")\n",
        "                    break\n",
        "\n",
        "        # Normalize src -> full url\n",
        "        if src:\n",
        "            src = src.strip()\n",
        "            # si src est du type \"mp3/xxx.mp3\" (relatif) ou \"./mp3/...\" -> construire URL complète\n",
        "            if src.startswith(\"http://\") or src.startswith(\"https://\"):\n",
        "                audio_url_full = src\n",
        "            else:\n",
        "                # urljoin sur la page courante permet de couvrir ../ ou chemins relatifs\n",
        "                audio_url_full = urljoin(url, src)\n",
        "            # extraire le nom de fichier décodé\n",
        "            parsed = urlparse(audio_url_full)\n",
        "            audio_file_name = unquote(os.path.basename(parsed.path))\n",
        "        else:\n",
        "            # dernier recours : parcourir tous les <source> et prendre le premier contenant mp3/wav\n",
        "            found = None\n",
        "            for s in soup.find_all(\"source\"):\n",
        "                ssrc = s.get(\"src\") or s.get(\"data-src\") or \"\"\n",
        "                if re.search(r\"\\.(mp3|wav)$\", ssrc, re.IGNORECASE):\n",
        "                    found = ssrc\n",
        "                    break\n",
        "            if found:\n",
        "                audio_url_full = urljoin(url, found)\n",
        "                audio_file_name = unquote(os.path.basename(urlparse(audio_url_full).path))\n",
        "\n",
        "        # 2) durée audio : sélecteur principal\n",
        "        time_tag = soup.select_one(SEL_TIME_PRIMARY)\n",
        "        if time_tag:\n",
        "            audio_length = time_tag.get_text(strip=True)\n",
        "        else:\n",
        "            # fallback selectors\n",
        "            for s in FALLBACK_TIME_SELECTORS:\n",
        "                t = soup.select_one(s)\n",
        "                if t and t.get_text(strip=True):\n",
        "                    audio_length = t.get_text(strip=True)\n",
        "                    break\n",
        "\n",
        "        # autre fallback : chercher le premier div.total-time dans la page\n",
        "        if not audio_length:\n",
        "            t = soup.find(\"div\", class_=\"total-time\")\n",
        "            if t:\n",
        "                audio_length = t.get_text(strip=True)\n",
        "\n",
        "        results.append({\n",
        "            \"index\": idx,\n",
        "            \"url\": url,\n",
        "            \"audio_length\": audio_length,\n",
        "            \"audio_file\": audio_file_name,\n",
        "            \"audio_url\": audio_url_full\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"erreur sur {url}: {e}\")\n",
        "        results.append({\"index\": idx, \"url\": url, \"audio_length\": None, \"audio_file\": None, \"audio_url\": None})\n",
        "\n",
        "    # pause polie\n",
        "\n",
        "# Enregistrer les résultats\n",
        "df_out = pd.DataFrame(results)\n",
        "df_out.to_csv(OUTPUT_CSV, index=False)\n",
        "print(f\"Terminé — résultats sauvés dans {OUTPUT_CSV}\")\n",
        "print(df_out.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "presentation",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
